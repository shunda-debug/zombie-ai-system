import streamlit as st
import re
import unicodedata
from google import genai

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Zombie AI", page_icon="ğŸ§Ÿ", layout="wide")

# --- APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿ï¼ˆSecretsã‹ã‚‰ï¼‰ ---
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ã›ãšã€Streamlitã®é‡‘åº«ã‹ã‚‰ã“ã£ãã‚Šå–ã‚Šå‡ºã—ã¾ã™
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ ç®¡ç†è€…ç”¨ã‚¨ãƒ©ãƒ¼: Streamlitã®Secretsã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

client = genai.Client(api_key=api_key)

# --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° ---
def get_integer(text):
    if not text: return ""
    text = unicodedata.normalize('NFKC', text)
    text = re.sub(r'[^0-9.]', '', text)
    if '.' in text: text = text.split('.')[0]
    return text

def call_ai(client, model, prompt):
    try:
        res = client.models.generate_content(model=model, contents=prompt)
        return res.text.strip()
    except:
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆæ“ä½œç›¤ï¼‰ ---
with st.sidebar:
    st.title("ğŸ§Ÿ Zombie AI")
    st.caption("v2.0 Enterprise Model")
    
    st.markdown("---")
    
    # æ–°ã—ã„ä¼šè©±ã‚’å§‹ã‚ã‚‹ãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("### ğŸ›¡ï¸ System Status")
    st.success("ğŸŸ¢ Tier 1 (Flash x2): Online")
    st.success("ğŸŸ¢ Tier 2 (Pro): Standby")
    
    # ä¸€ç•ªä¸‹ã®ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
    st.markdown("---")
    st.markdown(
        """
        ### ğŸ’€ Never Die Architecture
        ã“ã®AIã¯**ä¸æ­»èº«**ã§ã™ã€‚
        2ã¤ã®é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ã¨1ã¤ã®å¤©æ‰ãƒ¢ãƒ‡ãƒ«ãŒ
        ã‚ãªãŸã®è³ªå•ã‚’ç›£è¦–ã—ã€
        **çµ¶å¯¾ã«é–“é•ã£ãŸå›ç­”ã‚’è¨±ã—ã¾ã›ã‚“ã€‚**
        
        *Developed by Zombie Corp.*
        """
    )

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---
st.title("ğŸ’¬ Zombie AI Chat")
st.caption("å­¦æ ¡ã®èª²é¡Œã€ãƒ¬ãƒãƒ¼ãƒˆã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã«ã€‚å˜˜ã‚’ã¤ã‹ãªã„AIã€‚")

# ä¼šè©±å±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# 1. éå»ã®ä¼šè©±ã‚’ç”»é¢ã«æç”»ã™ã‚‹ï¼ˆã“ã‚ŒãŒãªã„ã¨æ¶ˆãˆã¦ã—ã¾ã„ã¾ã™ï¼‰
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # ã‚‚ã—è©³ç´°æƒ…å ±ï¼ˆã‚¢ã‚³ãƒ¼ãƒ‡ã‚£ã‚ªãƒ³ï¼‰ãŒã‚ã‚Œã°è¡¨ç¤º
        if "details" in message:
            with st.expander("ğŸ” åˆ†æãƒ­ã‚°ã‚’è¦‹ã‚‹"):
                st.markdown(message["details"])

# 2. æ–°ã—ã„è³ªå•ã®å…¥åŠ›
question = st.chat_input("ä½•ã§ã‚‚èã„ã¦ãã ã•ã„...")

if question:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¡¨ç¤ºï¼†ä¿å­˜
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.messages.append({"role": "user", "content": question})

    # AIã®å‡¦ç†
    with st.chat_message("assistant"):
        status_placeholder = st.empty()
        status_placeholder.info("âš¡ æ€è€ƒä¸­... (Flashãƒ¢ãƒ‡ãƒ«ãŒä¸¦åˆ—è¨ˆç®—ä¸­)")
        
        # Flashå®Ÿè¡Œ
        res_a = call_ai(client, "gemini-2.0-flash", f"{question} (ç°¡æ½”ã«)")
        res_c = call_ai(client, "gemini-2.0-flash", f"{question} (ç°¡æ½”ã«)")
        
        # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        match = False
        final_answer = ""
        log_text = "" # ãƒ­ã‚°ä¿å­˜ç”¨
        
        # ãƒ­ã‚°ä½œæˆ
        log_text += f"**Flash A:** {res_a}\n\n"
        log_text += f"**Flash C:** {res_c}\n\n"

        if res_a and res_c:
            num_a = get_integer(res_a)
            num_c = get_integer(res_c)
            if (num_a and num_c and num_a == num_c) or (res_a == res_c):
                match = True
                final_answer = res_a
                log_text += "âœ… **åˆ¤å®š:** ä¸€è‡´ (Tier 1æ¡ç”¨)"
        
        if match:
            status_placeholder.empty() # æ€è€ƒä¸­è¡¨ç¤ºã‚’æ¶ˆã™
            st.markdown(final_answer)
            # ä¿å­˜
            st.session_state.messages.append({
                "role": "assistant",
                "content": final_answer,
                "details": log_text
            })
            
        else:
            status_placeholder.warning("ğŸš¨ æ„è¦‹ä¸ä¸€è‡´ã€‚å°‚é–€å®¶(Proãƒ¢ãƒ‡ãƒ«)ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™...")
            log_text += "ğŸš¨ **åˆ¤å®š:** ä¸ä¸€è‡´ -> Proãƒ¢ãƒ‡ãƒ«èµ·å‹•\n\n"
            
            res_pro = call_ai(client, "gemini-2.0-pro-exp-02-05", f"{question} (å°‚é–€å®¶ã¨ã—ã¦å³å¯†ã«)")
            
            status_placeholder.empty()
            if res_pro:
                st.markdown(res_pro)
                log_text += f"**ğŸ† Pro Answer:** {res_pro}"
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": res_pro,
                    "details": log_text
                })
            else:
                st.error("é€šä¿¡ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
