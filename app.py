import streamlit as st
from google import genai
import concurrent.futures

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š (Minimalist Design) ---
st.set_page_config(page_title="Sci-Core", page_icon="âš›ï¸", layout="wide")

# --- 2. ãƒ‡ã‚¶ã‚¤ãƒ³ (æ´—ç·´ã•ã‚ŒãŸãƒŸãƒ‹ãƒãƒªã‚ºãƒ ) ---
st.markdown("""
<style>
    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã¨èƒŒæ™¯ã‚’èª¿æ•´ */
    .stApp {
        background-color: #0E1117; /* æ·±ã„é»’ (Gemini Darké¢¨) */
        color: #E0E0E0;
    }
    
    /* å…¥åŠ›ã‚¨ãƒªã‚¢ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã« */
    .stChatInputContainer {
        background-color: #0E1117;
        border-top: 1px solid #333;
    }
    
    /* ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹ãå‡ºã— (ç›®ç«‹ãŸãªã„ã‚°ãƒ¬ãƒ¼) */
    .stChatMessage[data-testid="user"] {
        background-color: #262730;
        border: none;
    }
    
    /* AIã®å¹ãå‡ºã— (èƒŒæ™¯ãªã—ã€æ–‡å­—ã®ã¿å¼·èª¿) */
    .stChatMessage[data-testid="assistant"] {
        background-color: transparent;
        border: none;
    }
    
    /* æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®Expanderã‚’ã‚¹ã‚¿ã‚¤ãƒªãƒƒã‚·ãƒ¥ã« */
    .streamlit-expanderHeader {
        background-color: #161B22;
        color: #888;
        font-size: 0.9em;
        border-radius: 5px;
    }
    
    /* ãƒ˜ãƒƒãƒ€ãƒ¼éš ã— */
    header {visibility: hidden;}
    
    /* æ•°å¼ã‚«ãƒ©ãƒ¼ */
    .katex { color: #A8C7FA !important; }
</style>
""", unsafe_allow_html=True)

# --- APIã‚­ãƒ¼ ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ API Key Error")
    st.stop()

client = genai.Client(api_key=api_key)

# --- å±¥æ­´ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- AIè„³ã¿ã (ä¸¦åˆ—å‡¦ç†å¯¾å¿œ) ---
def call_ai(prompt, role):
    try:
        # å½¹å‰²ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ å‘½ä»¤ (Disney Strategy)
        if role == "A": # Dreamer
            sys = """
            ã‚ãªãŸã¯ã€Œè‚¯å®šçš„ãªãƒ‰ãƒªãƒ¼ãƒãƒ¼ï¼ˆDreamerï¼‰ã€ã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«å¯¾ã—ã€åˆ¶é™ï¼ˆäºˆç®—ã€æŠ€è¡“ã€æ™‚é–“ï¼‰ã‚’ç„¡è¦–ã—ã¦ã€
            æœ€ã‚‚ç†æƒ³çš„ã§ã€ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ã€é©æ–°çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
            æ‰¹åˆ¤ã¯ä¸€åˆ‡ã›ãšã€å¯èƒ½æ€§ã‚’åºƒã’ã‚‹ã“ã¨ã ã‘ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚
            """
        elif role == "B": # Realist/Critic
            sys = """
            ã‚ãªãŸã¯ã€Œæ‰¹åˆ¤çš„ãªãƒªã‚¢ãƒªã‚¹ãƒˆï¼ˆCriticï¼‰ã€ã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«å¯¾ã—ã€ç¾å®Ÿçš„ãªè¦–ç‚¹ï¼ˆäºˆç®—ã€æ™‚é–“ã€ç‰©ç†æ³•å‰‡ã€ãƒªã‚¹ã‚¯ï¼‰ã‹ã‚‰
            æ‡¸å¿µç‚¹ã‚„æ¬ é™¥ã‚’å³ã—ãæŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
            ç”˜ã„è€ƒãˆã‚’æ¨ã¦ã€æœ€æ‚ªã®ã‚±ãƒ¼ã‚¹ã‚„éšœå®³ã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚
            """
        else: # C: Judge
            sys = """
            ã‚ãªãŸã¯ã€Œçµ±åˆã™ã‚‹èª¿æ•´è€…ï¼ˆJudgeï¼‰ã€ã§ã™ã€‚
            ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ã€ãã‚Œã«å¯¾ã™ã‚‹ã€ŒAï¼ˆç†æƒ³æ¡ˆï¼‰ã€ã¨ã€ŒBï¼ˆæ‰¹åˆ¤æ¡ˆï¼‰ã€ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
            
            ã‚ãªãŸã®ä»•äº‹ã¯ã€Bã®æ‡¸å¿µã‚’Aã®ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã©ã†ä¹—ã‚Šè¶Šãˆã‚‹ã‹ã€
            ã‚ã‚‹ã„ã¯Aã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’Bã®åˆ¶ç´„ã®ä¸­ã§ã©ã†å®Ÿç¾ã™ã‚‹ã‹ã€
            ã€Œç¬¬3ã®è§£æ±ºç­–ï¼ˆã‚¢ã‚¦ãƒ•ãƒ˜ãƒ¼ãƒ™ãƒ³ï¼‰ã€ã‚’å°ãå‡ºã™ã“ã¨ã§ã™ã€‚
            
            å›ç­”ã¯ã€Aã‚„Bã®è­°è«–ã«ã¯è§¦ã‚Œãšã€**ã‚ãªãŸãŒå‡ºã—ãŸã€Œæœ€çµ‚çµè«–ã€ã®ã¿**ã‚’ã€
            è«–ç†çš„ã‹ã¤æ´—ç·´ã•ã‚ŒãŸæ–‡ç« ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            """
        
        res = client.models.generate_content(
            model="gemini-1.5-flash", 
            contents=prompt,
            config={"system_instruction": sys}
        )
        return res.text.strip()
    except:
        return "Error"

# --- ä¸¦åˆ—å‡¦ç†é–¢æ•° (æ™‚é–“ã‚’çŸ­ç¸®ã™ã‚‹é­”æ³•) ---
def run_parallel_thinking(prompt):
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # Aã¨Bã‚’ã€Œãƒ¨ãƒ¼ã‚¤ãƒ‰ãƒ³ã€ã§åŒæ™‚ã«èµ°ã‚‰ã›ã‚‹
        future_a = executor.submit(call_ai, prompt, "A")
        future_b = executor.submit(call_ai, prompt, "B")
        
        # ä¸¡æ–¹ãŒçµ‚ã‚ã‚‹ã®ã‚’å¾…ã£ã¦çµæœã‚’å—ã‘å–ã‚‹
        return future_a.result(), future_b.result()

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("âš›ï¸ Sci-Core")
    st.caption("Disney Protocol v5.0")
    
    st.markdown("---")
    if st.button("New Chat", type="primary", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
# å±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãŒã‚ã‚Œã°è¡¨ç¤º (Google AI Studioé¢¨)
        if "thoughts" in message:
            with st.expander("âœ¨ Thoughts (Process A vs B)"):
                st.markdown(message["thoughts"])

# --- å…¥åŠ›ã‚¨ãƒªã‚¢ ---
prompt = st.chat_input("è³ªå•ã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

if prompt:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # AIå‡¦ç†
    with st.chat_message("assistant"):
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºï¼ˆã‚«ãƒƒã‚³ã‚ˆãï¼‰
        status_box = st.status("Thinking...", expanded=True)
        
        # 1. Aã¨BãŒä¸¦åˆ—ã§è­°è«– (ãƒ‘ãƒ©ãƒ¬ãƒ«å‡¦ç†)
        status_box.write("âš¡ Dreamer & Critic are debating...")
        res_a, res_b = run_parallel_thinking(prompt)
        
        # 2. CãŒçµ±åˆ (ã‚¸ãƒ£ãƒƒã‚¸)
        status_box.write("ğŸ‘¨â€âš–ï¸ Judge is synthesizing...")
        
        judge_input = f"""
        ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
        {prompt}
        
        ã€Aã®æ„è¦‹ï¼ˆç†æƒ³ï¼‰ã€‘
        {res_a}
        
        ã€Bã®æ„è¦‹ï¼ˆç¾å®Ÿï¼‰ã€‘
        {res_b}
        
        ã“ã‚Œã‚‰ã‚’çµ±åˆã—ã€æœ€é©ãªå›ç­”ã‚’ä½œæˆã›ã‚ˆã€‚
        """
        final_answer = call_ai(judge_input, "C")
        
        # å®Œäº†
        status_box.update(label="Complete", state="complete", expanded=False)
        
        # çµæœè¡¨ç¤º
        st.markdown(final_answer)
        
        # æ€è€ƒãƒ­ã‚°ã®ä½œæˆ
        thoughts_log = f"""
        **ğŸš€ Agent A (Dreamer):**
        {res_a}
        
        ---
        **ğŸ›¡ï¸ Agent B (Realist):**
        {res_b}
        """
        
        with st.expander("âœ¨ Thoughts (Process A vs B)"):
            st.markdown(thoughts_log)
            
        # å±¥æ­´ä¿å­˜
        st.session_state.messages.append({
            "role": "assistant", 
            "content": final_answer, 
            "thoughts": thoughts_log
        })
