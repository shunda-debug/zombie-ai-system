import streamlit as st
import requests
import concurrent.futures

# -------------------------------
#  åŸºæœ¬è¨­å®š / UIãƒ†ãƒ¼ãƒ
# -------------------------------
st.set_page_config(
    page_title="Sci-Core AI â€” Disney Protocol Edition",
    layout="centered"
)

# Dark Minimal Styling
st.markdown(
    """
    <style>
    body { background-color: #0E1117 !important; }
    .stMarkdown, .stChatMessage, .stTextInput, .stTextArea,
    .stButton, .stExpander {
        color: #E0E0E0 !important;
    }
    .main { background-color: #0E1117 !important; }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ§  Sci-Core AI â€” Disney Protocol Edition")

# -------------------------------
#  ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# -------------------------------
if "history" not in st.session_state:
    st.session_state.history = []


# -------------------------------
#  Gemini REST API å‘¼ã³å‡ºã—
#  ï¼ˆgoogle-generativeai ã¯ä½¿ç”¨ã—ãªã„ï¼‰
# -------------------------------
MODEL_NAME = "gemini-1.5-flash-latest"  # â† ä¿®æ­£ç‰ˆãƒ¢ãƒ‡ãƒ«å

def call_gemini_api(prompt: str):
    api_key = st.secrets["GEMINI_API_KEY"]

    url = (
        f"https://generativelanguage.googleapis.com/v1beta/"
        f"models/{MODEL_NAME}:generateContent?key={api_key}"
    )

    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ]
    }

    try:
        res = requests.post(url, json=payload, timeout=60)

        # â— è¦ä»¶ã©ãŠã‚Šï¼šã‚¨ãƒ©ãƒ¼æ™‚ã¯ Raw Response ã‚’ãã®ã¾ã¾è¿”ã™
        if not res.ok:
            return (
                f"[ERROR]\n"
                f"Status Code: {res.status_code}\n"
                f"Raw Error:\n{res.text}"
            )

        data = res.json()
        return data["candidates"][0]["content"]["parts"][0]["text"]

    except Exception as e:
        return f"[EXCEPTION]\n{str(e)}"


# -------------------------------
#  Disney Strategy â€” Prompt Templates
# -------------------------------
def build_prompt_dreamer(user_input):
    return f"""
You are Agent A â€” The Dreamer.
Generate bold, innovative, optimistic ideas.
Ignore constraints such as cost, time, and feasibility.

User Question:
{user_input}

Output Style:
- visionary
- creative
- inspiring
- no limitations
"""

def build_prompt_critic(user_input):
    return f"""
You are Agent B â€” The Realist / Critic.
Analyze risks, constraints, feasibility, costs, and failures.
Be strict, logical, and critical.

User Question:
{user_input}

Output Style:
- risk assessment
- weaknesses
- constraints
- potential failures
"""

def build_prompt_judge(user_input, a_out, b_out):
    return f"""
You are Agent C â€” The Judge / Synthesizer.

Your task:
Create a **third solution** which:
- preserves the innovative strengths of Agent A
- resolves the realistic concerns of Agent B
- is practical, balanced, and elegant

Context:

[Agent A â€” Dreamer Output]
{a_out}

[Agent B â€” Realist Output]
{b_out}

User Question:
{user_input}

Output Style:
- clear
- structured
- actionable
- balanced innovation
"""


# -------------------------------
#  UI â€” å±¥æ­´è¡¨ç¤ºï¼ˆæ—¢å®šã¯ Agent C ã®ã¿ï¼‰
# -------------------------------
for turn in st.session_state.history:
    st.markdown("### âœ¨ æœ€çµ‚çµè«–ï¼ˆAgent Cï¼‰")
    st.markdown(turn["agent_c"])

    with st.expander("âœ¨ æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¤º (Thoughts)"):
        st.markdown("#### ğŸŸ¦ Agent A â€” Dreamer")
        st.markdown(turn["agent_a"])

        st.markdown("#### ğŸŸ¥ Agent B â€” Realist / Critic")
        st.markdown(turn["agent_b"])

    st.divider()


# -------------------------------
#  å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆç”»é¢ä¸‹å›ºå®šï¼‰
# -------------------------------
user_input = st.chat_input("è³ªå•ãƒ»ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

if user_input:

    # Phase 1 â€” ä¸¦åˆ—æ€è€ƒï¼ˆA & B ã‚’ concurrent.futures ã§åŒæ™‚å®Ÿè¡Œï¼‰
    prompt_a = build_prompt_dreamer(user_input)
    prompt_b = build_prompt_critic(user_input)

    with st.spinner("Processing â€” Running parallel reasoning..."):
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            future_a = executor.submit(call_gemini_api, prompt_a)
            future_b = executor.submit(call_gemini_api, prompt_b)

            agent_a_out = future_a.result()
            agent_b_out = future_b.result()

    # Phase 2 â€” çµ±åˆï¼ˆAgent Cï¼‰
    prompt_c = build_prompt_judge(user_input, agent_a_out, agent_b_out)
    agent_c_out = call_gemini_api(prompt_c)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã¸ä¿å­˜
    st.session_state.history.append(
        {
            "user": user_input,
            "agent_a": agent_a_out,
            "agent_b": agent_b_out,
            "agent_c": agent_c_out,
        }
    )

    # ç›´è¿‘ã®çµæœã‚’å³æ™‚è¡¨ç¤º
    st.markdown("### âœ¨ æœ€çµ‚çµè«–ï¼ˆAgent Cï¼‰")
    st.markdown(agent_c_out)

    with st.expander("âœ¨ æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¤º (Thoughts)"):
        st.markdown("#### ğŸŸ¦ Agent A â€” Dreamer")
        st.markdown(agent_a_out)

        st.markdown("#### ğŸŸ¥ Agent B â€” Realist / Critic")
        st.markdown(agent_b_out)

    st.divider()

