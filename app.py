import streamlit as st
from google import genai
import concurrent.futures

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Sci-Core", page_icon="âš›ï¸", layout="wide")

# --- 2. ãƒ‡ã‚¶ã‚¤ãƒ³ (Disney Protocol / Dark Minimal) ---
st.markdown("""
<style>
    /* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã¨èƒŒæ™¯ */
    .stApp {
        background-color: #0E1117;
        color: #E0E0E0;
    }
    
    /* å…¥åŠ›ã‚¨ãƒªã‚¢ */
    .stChatInputContainer {
        background-color: #0E1117;
        border-top: 1px solid #333;
    }
    
    /* ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹ãå‡ºã— */
    .stChatMessage[data-testid="user"] {
        background-color: #262730;
        border: none;
    }
    
    /* AIã®å¹ãå‡ºã— */
    .stChatMessage[data-testid="assistant"] {
        background-color: transparent;
        border: none;
    }
    
    /* Expanderã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .streamlit-expanderHeader {
        background-color: #161B22;
        color: #888;
        font-size: 0.9em;
        border-radius: 5px;
    }
    
    /* ãƒ˜ãƒƒãƒ€ãƒ¼éš ã— */
    header {visibility: hidden;}
    
    /* æ•°å¼ã‚«ãƒ©ãƒ¼ */
    .katex { color: #A8C7FA !important; }
</style>
""", unsafe_allow_html=True)

# --- APIã‚­ãƒ¼è¨­å®š ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ ã‚¨ãƒ©ãƒ¼: Secretsã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
try:
    client = genai.Client(api_key=api_key)
except Exception as e:
    st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# --- å±¥æ­´ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- AIè„³ã¿ã (ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ­è¼‰) ---
def call_ai(prompt, role):
    try:
        # å½¹å‰²ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ å‘½ä»¤
        if role == "A": # Dreamer
            sys = """
            ã‚ãªãŸã¯ã€Œè‚¯å®šçš„ãªãƒ‰ãƒªãƒ¼ãƒãƒ¼ï¼ˆDreamerï¼‰ã€ã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«å¯¾ã—ã€åˆ¶é™ã‚’ç„¡è¦–ã—ã¦ã€
            æœ€ã‚‚ç†æƒ³çš„ã§ã€ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹é©æ–°çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
            æ‰¹åˆ¤ã¯ä¸€åˆ‡ã›ãšã€å¯èƒ½æ€§ã‚’åºƒã’ã‚‹ã“ã¨ã ã‘ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚
            """
        elif role == "B": # Realist
            sys = """
            ã‚ãªãŸã¯ã€Œæ‰¹åˆ¤çš„ãªãƒªã‚¢ãƒªã‚¹ãƒˆï¼ˆCriticï¼‰ã€ã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«å¯¾ã—ã€ç¾å®Ÿçš„ãªè¦–ç‚¹ï¼ˆäºˆç®—ã€æ™‚é–“ã€æŠ€è¡“ã€ãƒªã‚¹ã‚¯ï¼‰ã‹ã‚‰
            æ‡¸å¿µç‚¹ã‚„æ¬ é™¥ã‚’å³ã—ãæŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
            ç”˜ã„è€ƒãˆã‚’æ¨ã¦ã€éšœå®³ã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚
            """
        else: # C: Judge
            sys = """
            ã‚ãªãŸã¯ã€Œçµ±åˆã™ã‚‹èª¿æ•´è€…ï¼ˆJudgeï¼‰ã€ã§ã™ã€‚
            Aï¼ˆç†æƒ³ï¼‰ã¨Bï¼ˆç¾å®Ÿï¼‰ã®è­°è«–ã‚’è¸ã¾ãˆã€
            ã€Œç¬¬3ã®è§£æ±ºç­–ï¼ˆã‚¢ã‚¦ãƒ•ãƒ˜ãƒ¼ãƒ™ãƒ³ï¼‰ã€ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚
            å›ç­”ã¯ã€Aã‚„Bã®è­°è«–ã«ã¯è§¦ã‚Œãšã€ã‚ãªãŸãŒå‡ºã—ãŸã€Œæœ€çµ‚çµè«–ã€ã®ã¿ã‚’
            è«–ç†çš„ã‹ã¤æ´—ç·´ã•ã‚ŒãŸæ–‡ç« ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            """
        
        # APIå‘¼ã³å‡ºã— (gemini-1.5-flash)
        res = client.models.generate_content(
            model="gemini-1.5-flash", 
            contents=prompt,
            config={"system_instruction": sys}
        )
        return res.text.strip()
        
    except Exception as e:
        # ã€é‡è¦ã€‘ã‚¨ãƒ©ãƒ¼ã®æ­£ä½“ã‚’ãã®ã¾ã¾è¿”ã™
        return f"ğŸš¨ DEBUG_ERROR: {str(e)}"

# --- ä¸¦åˆ—å‡¦ç†é–¢æ•° ---
def run_parallel_thinking(prompt):
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_a = executor.submit(call_ai, prompt, "A")
        future_b = executor.submit(call_ai, prompt, "B")
        return future_a.result(), future_b.result()

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("âš›ï¸ Sci-Core")
    st.caption("Disney Protocol v5.1")
    
    st.markdown("---")
    if st.button("New Chat", type="primary", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
# å±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "thoughts" in message:
            with st.expander("âœ¨ Thoughts (Process A vs B)"):
                st.markdown(message["thoughts"])

# --- å…¥åŠ›ã‚¨ãƒªã‚¢ ---
prompt = st.chat_input("è³ªå•ã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

if prompt:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # AIå‡¦ç†
    with st.chat_message("assistant"):
        status_box = st.status("Thinking...", expanded=True)
        
        # 1. Aã¨BãŒä¸¦åˆ—ã§è­°è«–
        status_box.write("âš¡ Dreamer & Critic are debating...")
        res_a, res_b = run_parallel_thinking(prompt)
        
        # 2. CãŒçµ±åˆ
        status_box.write("ğŸ‘¨â€âš–ï¸ Judge is synthesizing...")
        
        # ã‚‚ã—Aã‹Bã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã„ãŸã‚‰ã€Judgeã«ã¯ã‚¨ãƒ©ãƒ¼æ–‡ã”ã¨æ¸¡ã—ã¦ç„¡ç†ã‚„ã‚Šå‡¦ç†ã•ã›ã‚‹ã‹ã€åœæ­¢ã™ã‚‹
        if "DEBUG_ERROR" in res_a or "DEBUG_ERROR" in res_b:
             final_answer = "âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ä¸‹ã®Thoughtsã‚’é–‹ã„ã¦è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        else:
            judge_input = f"è³ªå•:{prompt}\næ¡ˆA:{res_a}\næ¡ˆB:{res_b}\nçµ±åˆã—ã¦çµè«–ã‚’å‡ºã›ã€‚"
            final_answer = call_ai(judge_input, "C")
        
        # å®Œäº†
        status_box.update(label="Complete", state="complete", expanded=False)
        
        # çµæœè¡¨ç¤º
        st.markdown(final_answer)
        
        # æ€è€ƒãƒ­ã‚°
        thoughts_log = f"**ğŸš€ Agent A:**\n{res_a}\n\n---\n**ğŸ›¡ï¸ Agent B:**\n{res_b}"
        
        with st.expander("âœ¨ Thoughts (Process A vs B)"):
            st.markdown(thoughts_log)
            
        # å±¥æ­´ä¿å­˜
        st.session_state.messages.append({
            "role": "assistant", 
            "content": final_answer, 
            "thoughts": thoughts_log
        })
