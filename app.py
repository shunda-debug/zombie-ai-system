import streamlit as st
import time
from google import genai
from PIL import Image

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Sci-Core AI", page_icon="âš›ï¸", layout="wide")

# --- 2. ãƒ†ãƒ¼ãƒç®¡ç†ã¨CSS ---
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ†ãƒ¼ãƒåˆ‡ã‚Šæ›¿ãˆ
with st.sidebar:
    st.title("âš›ï¸ Sci-Core AI")
    st.caption("v3.3 Refined UI")
    
    # ãƒ†ãƒ¼ãƒé¸æŠ
    theme_mode = st.radio("ğŸ¨ Theme Color", ["Dark", "Light"], horizontal=True)

# CSSã®å‹•çš„ç”Ÿæˆ
if theme_mode == "Dark":
    bg_color = "#0E1117"
    text_color = "#FFFFFF"
    input_bg = "#262730"
    border_color = "#4E5359"
else:
    bg_color = "#FFFFFF"
    text_color = "#000000"
    input_bg = "#F0F2F6"
    border_color = "#D0D0D0"

st.markdown(f"""
<style>
    /* å…¨ä½“ã®èƒŒæ™¯ã¨æ–‡å­—è‰² */
    .stApp {{ background-color: {bg_color} !important; color: {text_color} !important; }}
    
    /* æ–‡å­—è‰²ã‚’å¼·åˆ¶é©ç”¨ï¼ˆpã‚¿ã‚°ã‚„hã‚¿ã‚°ãªã©ï¼‰ */
    p, h1, h2, h3, h4, h5, h6, li, span, div {{ color: {text_color} !important; }}
    
    /* å…¥åŠ›ã‚¨ãƒªã‚¢ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .stTextArea textarea {{ background-color: {input_bg} !important; color: {text_color} !important; border: 1px solid {border_color}; }}
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯ */
    [data-testid="stSidebar"] {{ background-color: {input_bg} !important; }}
    
    /* æ•°å¼ã®æ–‡å­—è‰²ï¼ˆé’ç³»ã§çµ±ä¸€ï¼‰ */
    .katex {{ color: #4B91F1 !important; font-size: 1.2em !important; }}
    
    /* é€ä¿¡ãƒœã‚¿ãƒ³ã‚’ç›®ç«‹ãŸã›ã‚‹ */
    div[data-testid="stFormSubmitButton"] button {{
        background-color: #238636; 
        color: white !important; 
        border: none;
        width: 100%;
    }}
    
    /* ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ç›®ç«‹ãŸãªãã‚¹ã‚¿ã‚¤ãƒªãƒƒã‚·ãƒ¥ã« */
    [data-testid="stFileUploader"] {{
        padding: 0px;
    }}
</style>
""", unsafe_allow_html=True)

# --- APIã‚­ãƒ¼ ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.stop()

client = genai.Client(api_key=api_key)

# --- å±¥æ­´ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- AIè„³ã¿ã ---
def call_science_model(client, prompt, image=None, role="solver"):
    try:
        if role == "solver":
            sys_instruction = "ã‚ãªãŸã¯ç§‘å­¦æŠ€è¡“è¨ˆç®—AIã§ã™ã€‚æ•°å¼ã¯$$ã‚’ä½¿ç”¨ã—ã€é€”ä¸­å¼ã‚’ä¸å¯§ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
        else: 
            sys_instruction = "ã‚ãªãŸã¯æŸ»èª­è€…ã§ã™ã€‚è¤‡æ•°ã®å›ç­”ã‚’æ¯”è¼ƒã—ã€æœ€é©ãªæœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        
        contents = [prompt, image] if image else prompt
        res = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=contents,
            config={"system_instruction": sys_instruction}
        )
        return res.text.strip()
    except:
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ (æ©Ÿèƒ½) ---
with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ–¥ï¸ System Status")
    col1, col2, col3 = st.columns(3)
    col1.metric("A", "on-line")
    col2.metric("B", "on-line")
    col3.metric("C", "on-line")
    
    if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’æ¶ˆå»"):
        st.session_state.messages = []
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆç”»é¢ ---
st.title("zombie-AI v1.1")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if "image" in message:
            st.image(message["image"], width=250)
        st.markdown(message["content"])
        if "details" in message:
            with st.expander("ğŸ” è§£æè©³ç´°"):
                st.markdown(message["details"])

# --- æ–°ã—ã„å…¥åŠ›ã‚¨ãƒªã‚¢ (ç”»é¢ä¸‹éƒ¨ã«å›ºå®š) ---
st.markdown("---")
# ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½¿ã†ã“ã¨ã§ã€Œé€ä¿¡ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¾ã§é€ä¿¡ã•ã‚Œãªã„ã€ã‚’å®Ÿç¾
with st.form(key="chat_form", clear_on_submit=True):
    col_input, col_btn = st.columns([8, 1])
    
    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ (Enterã§æ”¹è¡Œã•ã‚Œã‚‹)
    user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›...", height=100, label_visibility="collapsed", placeholder="Ctrl+Enterã§é€ä¿¡ã¯ã§ãã¾ã›ã‚“ãŒã€Enterã§æ”¹è¡Œã§ãã¾ã™ã€‚")
    
    # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨é€ä¿¡ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã£ã½ãé…ç½®
    c1, c2 = st.columns([1, 4])
    with c1:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        uploaded_file = st.file_uploader("ğŸ“· ç”»åƒ", type=["jpg", "png"], label_visibility="collapsed")
    with c2:
        # é€ä¿¡ãƒœã‚¿ãƒ³
        submit_btn = st.form_submit_button("ğŸš€ é€ä¿¡")

# --- å‡¦ç†å®Ÿè¡Œ ---
if submit_btn and user_input:
    image = Image.open(uploaded_file) if uploaded_file else None
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŠ•ç¨¿è¡¨ç¤º
    with st.chat_message("user"):
        if image: st.image(image, width=250)
        st.markdown(user_input)
    
    # å±¥æ­´ä¿å­˜
    msg_data = {"role": "user", "content": user_input}
    if image: msg_data["image"] = image
    st.session_state.messages.append(msg_data)
    
    # AIå‡¦ç†
    with st.chat_message("assistant"):
        status = st.empty()
        status.info("âš¡ Sci-Core Processing...")
        
        # Solver & Judge (ç°¡æ˜“åŒ–ã®ãŸã‚ç›´åˆ—å‡¦ç†ã«è¦‹ã›ã¦ã„ã¾ã™ãŒãƒ­ã‚¸ãƒƒã‚¯ã¯ç¶­æŒ)
        res_a = call_science_model(client, user_input, image, "solver")
        res_b = call_science_model(client, user_input, image, "solver")
        
        judge_prompt = f"è³ªå•: {user_input}\nå›ç­”A: {res_a}\nå›ç­”B: {res_b}\nã“ã‚Œã‚‰ã‚’çµ±åˆã—ã¦å›ç­”ã›ã‚ˆã€‚"
        final_answer = call_science_model(client, judge_prompt, None, "judge")
        
        if final_answer:
            status.empty()
            st.markdown(final_answer)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_answer,
                "details": f"**A:** {res_a}\n\n**B:** {res_b}"
            })
        else:
            status.error("Error occurred")
            
    st.rerun()
