import streamlit as st
import time
from google import genai

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Zombie AI Quad", page_icon="âš–ï¸", layout="wide")

# --- APIã‚­ãƒ¼èª­ã¿è¾¼ã¿ ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ ã‚¨ãƒ©ãƒ¼: Secretsã«APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = genai.Client(api_key=api_key)

# --- é–¢æ•°: é ‘ä¸ˆãªAIå‘¼ã³å‡ºã— ---
def call_flash(client, prompt, role="analysis"):
    try:
        # å½¹å‰²ã«å¿œã˜ã¦ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆã‚‹
        sys_instruction = "ã‚ãªãŸã¯ç°¡æ½”ã«äº‹å®Ÿã®ã¿ã‚’ç­”ãˆã‚‹AIã§ã™ã€‚"
        if role == "judge":
            sys_instruction = "ã‚ãªãŸã¯å…¬å¹³ãªè£åˆ¤å®˜ã§ã™ã€‚æç¤ºã•ã‚ŒãŸè¤‡æ•°ã®å›ç­”ã‚’æ¯”è¼ƒã—ã€æœ€ã‚‚æ­£ç¢ºã§è«–ç†çš„ãªæœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        
        res = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt,
            config={"system_instruction": sys_instruction}
        )
        return res.text.strip()
    except:
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("âš–ï¸ Zombie AI")
    st.caption("v5.0 Quad-Core Architecture")
    
    st.info("ğŸŸ¢ Worker A: Online")
    st.info("ğŸŸ¢ Worker B: Online")
    st.info("ğŸŸ¢ Worker C: Online")
    st.success("ğŸ‘¨â€âš–ï¸ Judge: Active")
    
    if st.button("ğŸ—‘ï¸ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("âš–ï¸ Zombie AI System")
st.caption("3å°ã®å®Ÿè¡Œéƒ¨éšŠã¨1å°ã®è£åˆ¤å®˜ã«ã‚ˆã‚‹ã€ãƒ—ãƒ­ä¸è¦ã®å®Œå…¨åˆè­°ã‚·ã‚¹ãƒ†ãƒ ã€‚")

if "messages" not in st.session_state:
    st.session_state.messages = []

# å±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "details" in message:
            with st.expander("ğŸ” 3è€…ã®æ„è¦‹ã¨è£åˆ¤è¨˜éŒ²ã‚’è¦‹ã‚‹"):
                st.markdown(message["details"])

# è³ªå•å…¥åŠ›
question = st.chat_input("è³ªå•ã‚’å…¥åŠ›...")

if question:
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.messages.append({"role": "user", "content": question})

    with st.chat_message("assistant"):
        status = st.empty()
        status.info("âš¡ 3å°ã®Flashãƒ¢ãƒ‡ãƒ«ãŒä¸¦åˆ—èª¿æŸ»ä¸­...")
        
        # 1. 3å°ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒä¸€æ–‰ã«å›ç­”ã‚’ä½œæˆ
        # (Streamlitã¯åŸºæœ¬ç›´åˆ—ã§ã™ãŒã€Flashã¯é«˜é€Ÿãªã®ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯ä¸€ç¬ã«è¦‹ãˆã¾ã™)
        res_a = call_flash(client, question, "analysis")
        res_b = call_flash(client, question, "analysis")
        res_c = call_flash(client, question, "analysis")
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆä¸‡ãŒä¸€å¤±æ•—ã—ãŸã‚‰ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºï¼‰
        ans_a = res_a if res_a else "å›ç­”ä¸èƒ½"
        ans_b = res_b if res_b else "å›ç­”ä¸èƒ½"
        ans_c = res_c if res_c else "å›ç­”ä¸èƒ½"
        
        # 2. ç”»é¢ã«3äººã®æ„è¦‹ã‚’è¡¨ç¤ºï¼ˆé€æ˜æ€§ï¼‰
        status.info("ğŸ‘¨â€âš–ï¸ è£åˆ¤å®˜(Judge)ãŒ3ã¤ã®æ„è¦‹ã‚’å¯©è­°ä¸­...")
        
        # ãƒ­ã‚°ç”¨ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
        log_text = f"""
        | Model | Answer Summary |
        | :--- | :--- |
        | **Worker A** | {ans_a[:50]}... |
        | **Worker B** | {ans_b[:50]}... |
        | **Worker C** | {ans_c[:50]}... |
        
        ---
        **è©³ç´°ãªå›ç­”:**
        
        **ğŸ¤– Flash A:**
        {ans_a}
        
        **ğŸ¤– Flash B:**
        {ans_b}
        
        **ğŸ¤– Flash C:**
        {ans_c}
        """

        # 3. è£åˆ¤å®˜ã«ã‚ˆã‚‹æœ€çµ‚æ±ºå®š (Judge Step)
        judge_prompt = f"""
        ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
        {question}

        ã€AI-Aã®å›ç­”ã€‘
        {ans_a}

        ã€AI-Bã®å›ç­”ã€‘
        {ans_b}

        ã€AI-Cã®å›ç­”ã€‘
        {ans_c}

        ã€ã‚ãªãŸã®ä»•äº‹ã€‘
        ã‚ãªãŸã¯æœ€é«˜è£åˆ¤å®˜ã§ã™ã€‚ä¸Šè¨˜3ã¤ã®å›ç­”ã‚’æ¯”è¼ƒã—ã€
        æœ€ã‚‚æ­£ç¢ºã§ã€çŸ›ç›¾ãŒãªãã€ä¿¡é ¼ã§ãã‚‹ã€Œæœ€çµ‚å›ç­”ã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        ã‚‚ã—3ã¤ã®æ„è¦‹ãŒé£Ÿã„é•ã£ã¦ã„ã‚‹å ´åˆã¯ã€å¤šæ•°æ±ºã®è«–ç†ã‚’ç”¨ã„ã¦æ­£è§£ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚
        å›ç­”ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã™ã‚‹è¿”ç­”ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        """
        
        final_answer = call_flash(client, judge_prompt, "judge")
        
        if final_answer:
            status.empty()
            st.markdown(final_answer)
            
            # ãƒ­ã‚°ã«è£åˆ¤å®˜ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_answer, 
                "details": log_text
            })
        else:
            status.error("ğŸ’€ è£åˆ¤å®˜ãŒå€’ã‚Œã¾ã—ãŸï¼ˆã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ï¼‰")
