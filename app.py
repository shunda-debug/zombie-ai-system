import streamlit as st
import time
from google import genai

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Sci-Core AI", page_icon="âš›ï¸", layout="wide")

# --- APIã‚­ãƒ¼ ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ã®è¨­å®šãŒå¿…è¦ã§ã™")
    st.stop()

client = genai.Client(api_key=api_key)

# --- é–¢æ•° ---
def call_science_model(client, prompt, role="solver"):
    try:
        # ç†ç³»ç‰¹åŒ–ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        if role == "solver":
            sys_instruction = """
            ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜å³°ã®ç‰©ç†å­¦è€…ã‹ã¤æ•°å­¦è€…ã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’å³å®ˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
            1. ã„ããªã‚Šç­”ãˆã‚’å‡ºã•ãšã€å¿…ãšã€Œæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ï¼ˆé€”ä¸­å¼ï¼‰ã€ã‚’ç¤ºã™ã“ã¨ã€‚
            2. æ•°å¼ã¯LaTeXå½¢å¼ï¼ˆ$è¨˜å·ã§å›²ã‚€ï¼‰ã‚’ä½¿ã£ã¦ãã‚Œã„ã«æ›¸ãã“ã¨ã€‚
            3. å˜ä½ï¼ˆkm/s, J, Nãªã©ï¼‰ã‚’æ­£ç¢ºã«æ‰±ã†ã“ã¨ã€‚
            4. æ›–æ˜§ãªçŸ¥è­˜ã§ç­”ãˆãšã€è«–ç†çš„ã«å°ãå‡ºã™ã“ã¨ã€‚
            """
        else: # Judge
            sys_instruction = """
            ã‚ãªãŸã¯å³æ ¼ãªæŸ»èª­è€…ï¼ˆReviewerï¼‰ã§ã™ã€‚
            3ã¤ã®AIãŒå°ãå‡ºã—ãŸã€Œè¨ˆç®—éç¨‹ã€ã¨ã€Œç­”ãˆã€ã‚’æ¯”è¼ƒã—ã€
            æœ€ã‚‚è«–ç†çš„ã§ã€è¨ˆç®—ãƒŸã‚¹ãŒãªã„ã‚‚ã®ã‚’æ¡ç”¨ã—ã¦æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            ã‚‚ã—æ„è¦‹ãŒå‰²ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€å¤šæ•°æ±ºã§ã¯ãªãã€Œè«–ç†ã®æ­£ã—ã•ã€ã§åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
            """
        
        res = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt,
            config={"system_instruction": sys_instruction}
        )
        return res.text.strip()
    except:
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("âš›ï¸ Sci-Core AI")
    st.caption("v1.0 Science Solver")
    
    st.info("ğŸŸ¢ Solver A (Physics): Ready")
    st.info("ğŸŸ¢ Solver B (Math): Ready")
    st.info("ğŸŸ¢ Solver C (Logic): Ready")
    st.success("ğŸ‘¨â€âš–ï¸ Reviewer: Active")
    
    if st.button("ğŸ—‘ï¸ è¨ˆç®—ç”¨ç´™ã‚’æ¨ã¦ã‚‹", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.markdown(
        """
        ### ğŸ“ For Students
        æ™®é€šã®AIã¯è¨ˆç®—ã‚’é–“é•ãˆã¾ã™ãŒã€
        ã“ã®AIã¯3ã¤ã®é ­è„³ã§æ¤œç®—ã™ã‚‹ãŸã‚
        **è¨ˆç®—ãƒŸã‚¹ã‚’æ¥µé™ã¾ã§æ¸›ã‚‰ã—ã¾ã™ã€‚**
        å®¿é¡Œã®æ¤œç®—ã‚„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã«ã€‚
        """
    )

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("âš›ï¸ ç†ç³»å°‚ç”¨ãƒ»é«˜ç²¾åº¦AIã‚½ãƒ«ãƒãƒ¼")
st.caption("æ•°å­¦ãƒ»ç‰©ç†ãƒ»åŒ–å­¦ã®é›£å•ã‚’ã€3æ®µéšã®ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã§è§£ãæ˜ã‹ã—ã¾ã™ã€‚")

if "messages" not in st.session_state:
    st.session_state.messages = []

# å±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "details" in message:
            with st.expander("ğŸ” æ¤œç®—ãƒ­ã‚°ã‚’è¦‹ã‚‹"):
                st.markdown(message["details"])

# è³ªå•å…¥åŠ›
question = st.chat_input("æ•°å¼ã€ç‰©ç†ã®å•é¡Œãªã©ã‚’å…¥åŠ›...")

if question:
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.messages.append({"role": "user", "content": question})

    with st.chat_message("assistant"):
        status = st.empty()
        status.info("âš¡ 3ã¤ã®AIãŒåˆ¥ãƒ«ãƒ¼ãƒˆã§è¨ˆç®—ä¸­...")
        
        # 1. 3å°ã®ã‚½ãƒ«ãƒãƒ¼ãŒè¨ˆç®—
        res_a = call_science_model(client, question, "solver")
        res_b = call_science_model(client, question, "solver")
        res_c = call_science_model(client, question, "solver")
        
        ans_a = res_a if res_a else "è¨ˆç®—ä¸èƒ½"
        ans_b = res_b if res_b else "è¨ˆç®—ä¸èƒ½"
        ans_c = res_c if res_c else "è¨ˆç®—ä¸èƒ½"
        
        # 2. æŸ»èª­ä¸­
        status.info("ğŸ‘¨â€âš–ï¸ æŸ»èª­è€…(Reviewer)ãŒé€”ä¸­å¼ã‚’æ¤œè¨¼ä¸­...")
        
        log_text = f"""
        | Model | Result Preview |
        | :--- | :--- |
        | **Solver A** | {ans_a[:30]}... |
        | **Solver B** | {ans_b[:30]}... |
        | **Solver C** | {ans_c[:30]}... |
        
        ---
        **æ¤œè¨¼ç”¨å…¨ãƒ‡ãƒ¼ã‚¿:**
        
        **âš›ï¸ Solver A:**
        {ans_a}
        
        **âš›ï¸ Solver B:**
        {ans_b}
        
        **âš›ï¸ Solver C:**
        {ans_c}
        """

        # 3. æŸ»èª­è€…ã«ã‚ˆã‚‹æœ€çµ‚å›ç­”
        judge_prompt = f"""
        ã€å•é¡Œã€‘
        {question}

        ã€è§£æ³•Aã€‘
        {ans_a}

        ã€è§£æ³•Bã€‘
        {ans_b}

        ã€è§£æ³•Cã€‘
        {ans_c}

        ã‚ãªãŸã¯æŸ»èª­è€…ã§ã™ã€‚3ã¤ã®è§£æ³•ã‚’æ¯”è¼ƒã—ã€
        æœ€ã‚‚ã€Œé€”ä¸­å¼ãŒä¸å¯§ã€ã§ã€Œç­”ãˆãŒæ­£ç¢ºã€ãªã‚‚ã®ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚å›ç­”ï¼ˆè§£èª¬ä»˜ãï¼‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        æ•°å¼ã¯LaTeXã§æ›¸ã„ã¦ãã ã•ã„ã€‚
        """
        
        final_answer = call_science_model(client, judge_prompt, "judge")
        
        if final_answer:
            status.empty()
            st.markdown(final_answer)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_answer, 
                "details": log_text
            })
        else:
            status.error("ğŸ’€ è¨ˆç®—å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
