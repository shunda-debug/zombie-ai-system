import streamlit as st
import requests
import json
import concurrent.futures

st.set_page_config(page_title="Sci-Core", page_icon="âš›ï¸", layout="wide")

# ãƒ‡ã‚¶ã‚¤ãƒ³
st.markdown("""<style>.stApp { background-color: #0E1117; color: #E0E0E0; } .stChatInputContainer { background-color: #0E1117; } .stChatMessage[data-testid="user"] { background-color: #262730; } .stChatMessage[data-testid="assistant"] { background-color: transparent; } header {visibility: hidden;}</style>""", unsafe_allow_html=True)

# APIã‚­ãƒ¼
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ API Key Error")
    st.stop()

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- ã€æ ¸å¿ƒã€‘ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã‚ãšã€ç›´æ¥URLã‚’å©ãé–¢æ•° ---
def call_api_direct(prompt, role):
    # Googleã®ä½æ‰€ï¼ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}"
    
    headers = {'Content-Type': 'application/json'}
    
    # å½¹å‰²å®šç¾©
    sys_msg = "ã‚ãªãŸã¯å„ªç§€ãªAIã§ã™ã€‚"
    if role == "A": sys_msg = "ã‚ãªãŸã¯è‚¯å®šçš„ãªãƒ‰ãƒªãƒ¼ãƒãƒ¼ã§ã™ã€‚"
    elif role == "B": sys_msg = "ã‚ãªãŸã¯æ‰¹åˆ¤çš„ãªãƒªã‚¢ãƒªã‚¹ãƒˆã§ã™ã€‚"
    elif role == "C": sys_msg = "ã‚ãªãŸã¯çµ±åˆã™ã‚‹èª¿æ•´å½¹ã§ã™ã€‚"

    # æ‰‹ç´™ã®ä¸­èº«ï¼ˆJSONï¼‰
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "systemInstruction": {"parts": [{"text": sys_msg}]}
    }

    try:
        # é€ä¿¡ï¼
        response = requests.post(url, headers=headers, json=data)
        
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text']
        else:
            return f"Error {response.status_code}: {response.text}"
    except Exception as e:
        return f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}"

# ä¸¦åˆ—å‡¦ç†
def run_parallel(prompt):
    with concurrent.futures.ThreadPoolExecutor() as executor:
        fa = executor.submit(call_api_direct, prompt, "A")
        fb = executor.submit(call_api_direct, prompt, "B")
        return fa.result(), fb.result()

# UI
with st.sidebar:
    st.title("âš›ï¸ Sci-Core")
    st.caption("v6.0 Direct-REST")
    if st.button("New Chat", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "sub" in msg:
            with st.expander("Thoughts"): st.markdown(msg["sub"])

prompt = st.chat_input("è³ªå•ã‚’å…¥åŠ›...")

if prompt:
    with st.chat_message("user"): st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        stat = st.status("Thinking...", expanded=True)
        stat.write("âš¡ Discussing...")
        res_a, res_b = run_parallel(prompt)
        
        stat.write("ğŸ‘¨â€âš–ï¸ Synthesizing...")
        final = call_api_direct(f"è³ªå•:{prompt}\nA:{res_a}\nB:{res_b}\nçµ±åˆã›ã‚ˆ", "C")
        
        stat.update(label="Complete", state="complete", expanded=False)
        st.markdown(final)
        
        sub_log = f"**A:**\n{res_a}\n\n**B:**\n{res_b}"
        with st.expander("Thoughts"): st.markdown(sub_log)
        
        st.session_state.messages.append({"role": "assistant", "content": final, "sub": sub_log})
