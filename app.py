import streamlit as st
import re
import unicodedata
from google import genai

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Zombie AI", page_icon="ğŸ§Ÿ", layout="wide")

# --- APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿ï¼ˆSecretsã‹ã‚‰ï¼‰ ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ (Secretsè¨­å®š)")
    st.stop()

client = genai.Client(api_key=api_key)

# --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° ---
def get_integer(text):
    if not text: return ""
    text = unicodedata.normalize('NFKC', text)
    text = re.sub(r'[^0-9.]', '', text)
    if '.' in text: text = text.split('.')[0]
    return text

def call_ai(client, model, prompt):
    try:
        res = client.models.generate_content(model=model, contents=prompt)
        return res.text.strip()
    except:
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("ğŸ§Ÿ Zombie AI")
    st.caption("v2.0 Enterprise Model")
    
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.success("ğŸŸ¢ Tier 1 (Flash): Online")
    st.success("ğŸŸ¢ Tier 2 (Pro): Standby")
    
    st.markdown("---")
    st.markdown(
        """
        ### ğŸ’€ Never Die Architecture
        **çµ¶å¯¾ä¸æ­»ãƒ»å®Œå…¨ä¿¡é ¼**
        
        2ã¤ã®AIãŒç›£è¦–ã—ã€
        ã‚ãªãŸã®è³ªå•ã«å˜˜ã‚’ã¤ãã¾ã›ã‚“ã€‚
        """
    )

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("ğŸ’¬ Zombie AI Chat")
st.caption("å­¦æ ¡ã®èª²é¡Œã€ãƒ¬ãƒãƒ¼ãƒˆã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã«ã€‚å˜˜ã‚’ã¤ã‹ãªã„AIã€‚")

# ä¼šè©±å±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# éå»ã®ä¼šè©±ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "details" in message:
            with st.expander("ğŸ” AIã®æ€è€ƒãƒ­ã‚°ã‚’è¦‹ã‚‹"):
                st.markdown(message["details"])

# æ–°ã—ã„è³ªå•
question = st.chat_input("è³ªå•ã‚’å…¥åŠ›...")

if question:
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.messages.append({"role": "user", "content": question})

    with st.chat_message("assistant"):
        status = st.empty()
        status.info("âš¡ æ€è€ƒä¸­... (Flashãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—è¨ˆç®—)")
        
        res_a = call_ai(client, "gemini-2.0-flash", f"{question} (ç°¡æ½”ã«)")
        res_c = call_ai(client, "gemini-2.0-flash", f"{question} (ç°¡æ½”ã«)")
        
        match = False
        final_answer = ""
        log_text = f"**Flash A:** {res_a}\n\n**Flash C:** {res_c}\n\n"

        if res_a and res_c:
            num_a = get_integer(res_a)
            num_c = get_integer(res_c)
            if (num_a and num_c and num_a == num_c) or (res_a == res_c):
                match = True
                final_answer = res_a
                log_text += "âœ… **åˆ¤å®š:** ä¸€è‡´ (Tier 1æ¡ç”¨)"
        
        if match:
            status.empty()
            st.markdown(final_answer)
            st.session_state.messages.append({"role": "assistant", "content": final_answer, "details": log_text})
        else:
            status.warning("ğŸš¨ æ„è¦‹ä¸ä¸€è‡´ã€‚å°‚é–€å®¶(Pro)ã‚’å‘¼ã³å‡ºã—ã¾ã™...")
            log_text += "ğŸš¨ **åˆ¤å®š:** ä¸ä¸€è‡´ -> Proãƒ¢ãƒ‡ãƒ«èµ·å‹•\n\n"
            res_pro = call_ai(client, "gemini-2.0-pro-exp-02-05", f"{question} (å°‚é–€å®¶ã¨ã—ã¦å³å¯†ã«)")
            status.empty()
            if res_pro:
                st.markdown(res_pro)
                log_text += f"**ğŸ† Pro Answer:** {res_pro}"
                st.session_state.messages.append({"role": "assistant", "content": res_pro, "details": log_text})
            else:
                st.error("ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ")
