import streamlit as st
import time
import re
from google import genai

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Sci-Core AI", page_icon="âš›ï¸", layout="wide")

# --- 2. ãƒ‡ã‚¶ã‚¤ãƒ³å¼·åˆ¶æ³¨å…¥ (Force Dark Mode) ---
st.markdown("""
<style>
    /* =================================
       1. å¼·åˆ¶ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰è¨­å®š
       ================================= */
    /* å…¨ä½“ã®èƒŒæ™¯ã‚’é»’ã«ã™ã‚‹ */
    .stApp {
        background-color: #0E1117 !important;
        color: #FFFFFF !important;
    }
    
    /* ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆä¸Šã®ãƒãƒ¼ï¼‰ã‚‚é»’ãã™ã‚‹ */
    header[data-testid="stHeader"] {
        background-color: #0E1117 !important;
    }

    /* =================================
       2. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’è¦‹ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
       ================================= */
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯è‰² */
    [data-testid="stSidebar"] {
        background-color: #161B22 !important;
        border-right: 1px solid #30363D;
    }
    
    /* ã€é‡è¦ã€‘ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’é–‹ããƒœã‚¿ãƒ³ï¼ˆ>ï¼‰ã‚’ç™½ãã™ã‚‹ */
    [data-testid="collapsedControl"] {
        color: #FFFFFF !important;
    }
    
    /* ã‚¹ãƒãƒ›ã§ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’é–‰ã˜ã‚‹ã€ŒXã€ãƒœã‚¿ãƒ³ã‚‚ç™½ãã™ã‚‹ */
    button[kind="header"] {
        color: #FFFFFF !important;
    }

    /* =================================
       3. æ–‡å­—ã¨å…¥åŠ›æ¬„ã®è¦–èªæ€§ã‚¢ãƒƒãƒ—
       ================================= */
    /* å…¨ã¦ã®æ–‡å­—ã‚’ç™½ãã€å¤ªã */
    body, p, div, span, label, h1, h2, h3, h4, h5, h6, li {
        color: #FFFFFF !important;
        -webkit-text-fill-color: #FFFFFF !important; /* ã‚¹ãƒãƒ›ç”¨å¼·åˆ¶ç™½ */
    }

    /* å…¥åŠ›æ¬„ï¼ˆãƒãƒ£ãƒƒãƒˆï¼‰ã®èƒŒæ™¯ã‚’ã‚°ãƒ¬ãƒ¼ã« */
    .stChatInput textarea {
        background-color: #262730 !important;
        color: #FFFFFF !important;
        caret-color: #FFFFFF !important; /* ã‚«ãƒ¼ã‚½ãƒ« */
        border: 1px solid #4E5359 !important;
    }
    
    /* ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç®± */
    .stChatMessage {
        background-color: #1E2329 !important;
        border: 1px solid #30363D;
    }

    /* æ•°å¼ï¼ˆLaTeXï¼‰ã‚’é’ãå…‰ã‚‰ã›ã‚‹ */
    .katex {
        color: #58A6FF !important;
        font-size: 1.2em !important;
    }

    /* ãƒœã‚¿ãƒ³ã®ãƒ‡ã‚¶ã‚¤ãƒ³ */
    .stButton button {
        background-color: #238636;
        color: white !important;
        font-weight: bold;
        border: none;
    }
</style>
""", unsafe_allow_html=True)

# --- APIã‚­ãƒ¼ ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ APIã‚­ãƒ¼è¨­å®šãŒå¿…è¦ã§ã™")
    st.stop()

client = genai.Client(api_key=api_key)

# --- å±¥æ­´ç®¡ç† ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- AIè„³ã¿ã ---
def call_science_model(client, prompt, role="solver"):
    try:
        if role == "solver":
            sys_instruction = """
            ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜å³°ã®ç§‘å­¦æŠ€è¡“è¨ˆç®—AIã§ã™ã€‚
            æ•°å¼ã¯å¿…ãš `$$` ã§å›²ã¿ã€`\\begin{align}` ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚
            æš—ç®—ç¦æ­¢ã€‚é€”ä¸­å¼ã‚’ä¸å¯§ã«æ›¸ãã€å˜ä½ã‚’æ­£ç¢ºã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
            """
        else: # Judge
            sys_instruction = """
            ã‚ãªãŸã¯å³æ ¼ãªæ•°å­¦æŸ»èª­è€…ã§ã™ã€‚
            3ã¤ã®å›ç­”ã‚’æ¯”è¼ƒã—ã€æœ€ã‚‚æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ã„æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            `\\begin{align}` ã¯ä½¿ç”¨ç¦æ­¢ã€‚ã™ã¹ã¦ã®æ•°å¼ã¯ `$$` ã¾ãŸã¯ `$` ã§å›²ã‚“ã§ãã ã•ã„ã€‚
            """
        
        res = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt,
            config={"system_instruction": sys_instruction}
        )
        return res.text.strip()
    except:
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("âš›ï¸ Sci-Core AI")
    st.caption("v2.4 Dark Mode Force")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("A", "ğŸŸ¢")
    col2.metric("B", "ğŸŸ¢")
    col3.metric("C", "ğŸŸ¢")
    
    st.markdown("---")
    
    # æ–°ã—ã„ä¼šè©±ãƒœã‚¿ãƒ³
    if st.button("â• æ–°ã—ã„ä¼šè©±", use_container_width=True):
        if st.session_state.messages:
            summary = st.session_state.messages[0]["content"][:15] + "..." if st.session_state.messages else "No Data"
            st.session_state.chat_history.append({"title": summary, "log": st.session_state.messages})
        st.session_state.messages = []
        st.rerun()

    st.markdown("### ğŸ“š History")
    if st.session_state.chat_history:
        for i, chat in enumerate(reversed(st.session_state.chat_history)):
            with st.expander(f"ğŸ“ {chat['title']}"):
                for msg in chat["log"]:
                    st.text(f"{msg['role']}: {msg['content']}")
    else:
        st.caption("å±¥æ­´ãªã—")

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("âš›ï¸ Sci-Core Solver")
st.markdown("#### ç†ç³»ç‰¹åŒ–ãƒ»é«˜ç²¾åº¦è¨ˆç®—AI")

# å±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "details" in message:
            with st.expander("ğŸ” è¨ˆç®—ãƒ—ãƒ­ã‚»ã‚¹"):
                st.markdown(message["details"])

# è³ªå•å…¥åŠ›
question = st.chat_input("è³ªå•ã‚’å…¥åŠ›...")

if question:
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.messages.append({"role": "user", "content": question})

    with st.chat_message("assistant"):
        status = st.empty()
        status.info("âš¡ 3ã¤ã®AIãŒä¸¦åˆ—è¨ˆç®—ä¸­...")
        
        # 1. ã‚½ãƒ«ãƒãƒ¼å®Ÿè¡Œ
        res_a = call_science_model(client, question, "solver")
        res_b = call_science_model(client, question, "solver")
        res_c = call_science_model(client, question, "solver")
        
        ans_a = res_a if res_a else "Error"
        ans_b = res_b if res_b else "Error"
        ans_c = res_c if res_c else "Error"
        
        # 2. æŸ»èª­
        status.info("ğŸ‘¨â€âš–ï¸ æŸ»èª­è€…ãŒæ¤œç®—ä¸­...")
        
        log_text = f"""
        **Solver A:** {ans_a}
        **Solver B:** {ans_b}
        **Solver C:** {ans_c}
        """

        # 3. æœ€çµ‚å›ç­”
        judge_prompt = f"""
        ã€å•é¡Œã€‘{question}
        ã€è§£æ³•Aã€‘{ans_a}
        ã€è§£æ³•Bã€‘{ans_b}
        ã€è§£æ³•Cã€‘{ans_c}
        
        ä¸Šè¨˜ã‚’çµ±åˆã—ã€æ­£ã—ã„è¨ˆç®—çµæœã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚
        æ•°å¼ã¯å¿…ãš `$$` ã§å›²ã¿ã€alignç’°å¢ƒã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
        """
        
        final_answer = call_science_model(client, judge_prompt, "judge")
        
        if final_answer:
            status.empty()
            st.markdown(final_answer)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_answer, 
                "details": log_text
            })
        else:
            status.error("ğŸ’€ è¨ˆç®—å¤±æ•—")
