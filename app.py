import streamlit as st
from google import genai
from PIL import Image

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Sci-Core AI", page_icon="âš›ï¸", layout="wide")

# --- 2. ãƒ‡ã‚¶ã‚¤ãƒ³ (Dark Mode & UIèª¿æ•´) ---
st.markdown("""
<style>
    /* å…¨ä½“ã‚’ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã«å›ºå®š */
    .stApp {
        background-color: #0E1117 !important;
        color: #E0E0E0 !important;
    }
    
    /* å…¥åŠ›ã‚¨ãƒªã‚¢ã®èƒŒæ™¯è‰² */
    .stTextArea textarea {
        background-color: #262730 !important;
        color: #FFFFFF !important;
        border: 1px solid #4E5359;
    }
    
    /* é€ä¿¡ãƒœã‚¿ãƒ³ã‚’ç·‘è‰²ã«ã—ã¦ç›®ç«‹ãŸã›ã‚‹ */
    div[data-testid="stFormSubmitButton"] button {
        background-color: #238636;
        color: white !important;
        border: none;
        width: 100%;
        font-weight: bold;
    }
    
    /* æ•°å¼ã®æ–‡å­—è‰² */
    .katex { color: #4DA6FF !important; font-size: 1.1em !important; }
</style>
""", unsafe_allow_html=True)

# --- APIã‚­ãƒ¼ ---
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ ã‚¨ãƒ©ãƒ¼: Secretsã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

client = genai.Client(api_key=api_key)

# --- å±¥æ­´ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- AIé–¢æ•° (ã‚¨ãƒ©ãƒ¼è©³ç´°è¡¨ç¤ºä»˜ã) ---
def call_science_model(client, prompt, image=None, role="solver"):
    try:
        # å½¹å‰²å®šç¾©
        if role == "solver":
            sys_instruction = "ã‚ãªãŸã¯ç§‘å­¦æŠ€è¡“è¨ˆç®—AIã§ã™ã€‚æ•°å¼ã¯$$ã‚’ä½¿ç”¨ã—ã€è«–ç†çš„ã‹ã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
        else:
            sys_instruction = "ã‚ãªãŸã¯æŸ»èª­è€…ã§ã™ã€‚è¤‡æ•°ã®å›ç­”ã‚’çµ±åˆã—ã€å®Œç’§ãªæœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        
        # ç”»åƒãŒã‚ã‚‹å ´åˆã¨ãªã„å ´åˆã§åˆ†å²
        contents = [prompt, image] if image else prompt
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’å®‰å®šç‰ˆ(1.5-flash)ã«å›ºå®š
        res = client.models.generate_content(
            model="gemini-1.5-flash", 
            contents=contents,
            config={"system_instruction": sys_instruction}
        )
        return res.text.strip()
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ã®æ­£ä½“ã‚’è¿”ã™
        return f"ERROR: {str(e)}"

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("âš›ï¸ Sci-Core")
    st.caption("v4.1 Stable Edition")
    
    st.success("ğŸŸ¢ System: Online")
    
    st.markdown("---")
    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("âš›ï¸ Sci-Core AI Project")

# å±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if "image" in message and message["image"]:
            st.image(message["image"], width=250)
        st.markdown(message["content"])
        if "details" in message:
            with st.expander("ğŸ” æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹"):
                st.markdown(message["details"])

# --- å…¥åŠ›ã‚¨ãƒªã‚¢ (ãƒ•ã‚©ãƒ¼ãƒ å½¢å¼ã«æˆ»ã—ã¾ã—ãŸ) ---
st.markdown("---")

with st.form(key="chat_form", clear_on_submit=True):
    # ã‚¹ãƒãƒ›ã§ã‚‚æ”¹è¡Œã—ã‚„ã™ã„ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢
    user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›...", height=100, placeholder="ã‚¹ãƒãƒ›ãªã‚‰ã€Œæ”¹è¡Œã€ã§æ¬¡ã®è¡Œã¸ã€‚é€ä¿¡ã¯ãƒœã‚¿ãƒ³ã§ã€‚")
    
    col1, col2 = st.columns([1, 4])
    with col1:
        # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_file = st.file_uploader("ç”»åƒ", type=["jpg", "png"], label_visibility="collapsed")
    with col2:
        # é€ä¿¡ãƒœã‚¿ãƒ³ (ã“ã‚ŒãŒæ¬²ã—ã‹ã£ãŸã‚„ã¤ã§ã™ï¼)
        submit_btn = st.form_submit_button("ğŸš€ é€ä¿¡ (Analyze)")

# --- å‡¦ç†å®Ÿè¡Œ ---
if submit_btn and user_input:
    # ç”»åƒå‡¦ç†
    image = Image.open(uploaded_file) if uploaded_file else None
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤º
    with st.chat_message("user"):
        if image: st.image(image, width=250)
        st.markdown(user_input)
    
    # å±¥æ­´ä¿å­˜
    msg_data = {"role": "user", "content": user_input}
    if image: msg_data["image"] = image
    st.session_state.messages.append(msg_data)
    
    # AIå‡¦ç†
    with st.chat_message("assistant"):
        status = st.empty()
        status.info("Sci-Core is thinking...")
        
        # Solverå®Ÿè¡Œ
        res_a = call_science_model(client, user_input, image, "solver")
        res_b = call_science_model(client, user_input, image, "solver")
        
        # ã‚‚ã—ã‚¨ãƒ©ãƒ¼ãŒè¿”ã£ã¦ãã¦ã„ãŸã‚‰è¡¨ç¤ºã™ã‚‹
        if "ERROR:" in res_a:
            status.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {res_a}")
        else:
            status.info("Judge is verifying...")
            judge_prompt = f"è³ªå•: {user_input}\nå›ç­”A: {res_a}\nå›ç­”B: {res_b}\nã“ã‚Œã‚‰ã‚’çµ±åˆã—ã€å›ç­”ã›ã‚ˆã€‚"
            final_answer = call_science_model(client, judge_prompt, None, "judge")
            
            if final_answer and "ERROR:" not in final_answer:
                status.empty()
                st.markdown(final_answer)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": final_answer,
                    "details": f"**Core A:** {res_a}\n\n**Core B:** {res_b}"
                })
            else:
                status.error(f"æœ€çµ‚åˆ¤å®šã§ã‚¨ãƒ©ãƒ¼: {final_answer}")
    
    # å‡¦ç†ãŒçµ‚ã‚ã£ãŸã‚‰ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤ºã‚’æ›´æ–°
    st.rerun()
